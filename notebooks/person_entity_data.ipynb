{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Matching Example\n",
    "\n",
    "Using FEBRL synthetic data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from pyent.datasets import generate_febrl_data, remove_nan, sample_xy\n",
    "from pyent.datasets import train_test_validate_stratified_split as ttvs\n",
    "from pyent.features import generate_textual_features\n",
    "from pyent.train import train_txt_baseline\n",
    "from pyent.config import get_config\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Synthetic Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Droping NaN's shape of data is (86506, 23)\n",
      "After Droping NaN's shape of data is (52560, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_idL</th>\n",
       "      <th>rec_idR</th>\n",
       "      <th>given_name_l</th>\n",
       "      <th>surname_l</th>\n",
       "      <th>street_number_l</th>\n",
       "      <th>address_1_l</th>\n",
       "      <th>address_2_l</th>\n",
       "      <th>suburb_l</th>\n",
       "      <th>postcode_l</th>\n",
       "      <th>state_l</th>\n",
       "      <th>date_of_birth_l</th>\n",
       "      <th>soc_sec_id_l</th>\n",
       "      <th>given_name_r</th>\n",
       "      <th>surname_r</th>\n",
       "      <th>street_number_r</th>\n",
       "      <th>address_1_r</th>\n",
       "      <th>address_2_r</th>\n",
       "      <th>suburb_r</th>\n",
       "      <th>postcode_r</th>\n",
       "      <th>state_r</th>\n",
       "      <th>date_of_birth_r</th>\n",
       "      <th>soc_sec_id_r</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec-2331-org</td>\n",
       "      <td>rec-4869-dup-0</td>\n",
       "      <td>christian</td>\n",
       "      <td>reid</td>\n",
       "      <td>10</td>\n",
       "      <td>britten-jones drive</td>\n",
       "      <td>honey patch</td>\n",
       "      <td>moe</td>\n",
       "      <td>2250</td>\n",
       "      <td>wa</td>\n",
       "      <td>19870501</td>\n",
       "      <td>2773283</td>\n",
       "      <td>taylah</td>\n",
       "      <td>reid</td>\n",
       "      <td>25</td>\n",
       "      <td>albermarlze place</td>\n",
       "      <td>cypress garden</td>\n",
       "      <td>pennant hills</td>\n",
       "      <td>2210</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19571029</td>\n",
       "      <td>7596151</td>\n",
       "      <td>no_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rec-1120-org</td>\n",
       "      <td>rec-2288-dup-0</td>\n",
       "      <td>angelica</td>\n",
       "      <td>green</td>\n",
       "      <td>5</td>\n",
       "      <td>nash place</td>\n",
       "      <td>palm grove</td>\n",
       "      <td>vaucluse</td>\n",
       "      <td>5242</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19051230</td>\n",
       "      <td>7491589</td>\n",
       "      <td>jhoel</td>\n",
       "      <td>green</td>\n",
       "      <td>708</td>\n",
       "      <td>wangarastreet</td>\n",
       "      <td>gallagher house</td>\n",
       "      <td>burpengary</td>\n",
       "      <td>4670</td>\n",
       "      <td>qld</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9018656</td>\n",
       "      <td>no_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rec-3774-org</td>\n",
       "      <td>rec-1136-dup-0</td>\n",
       "      <td>noah</td>\n",
       "      <td>clarke</td>\n",
       "      <td>608</td>\n",
       "      <td>bindel street</td>\n",
       "      <td>anstee court</td>\n",
       "      <td>boggabri</td>\n",
       "      <td>5158</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19540920</td>\n",
       "      <td>8260965</td>\n",
       "      <td>lachlan</td>\n",
       "      <td>clarke</td>\n",
       "      <td>19</td>\n",
       "      <td>bunbury street</td>\n",
       "      <td>kildurham</td>\n",
       "      <td>nhill</td>\n",
       "      <td>3850</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19180501</td>\n",
       "      <td>2371774</td>\n",
       "      <td>no_match</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rec_idL         rec_idR given_name_l surname_l street_number_l  \\\n",
       "0  rec-2331-org  rec-4869-dup-0    christian      reid              10   \n",
       "1  rec-1120-org  rec-2288-dup-0     angelica     green               5   \n",
       "2  rec-3774-org  rec-1136-dup-0         noah    clarke             608   \n",
       "\n",
       "           address_1_l   address_2_l  suburb_l postcode_l state_l  \\\n",
       "0  britten-jones drive   honey patch       moe       2250      wa   \n",
       "1           nash place    palm grove  vaucluse       5242     nsw   \n",
       "2        bindel street  anstee court  boggabri       5158     nsw   \n",
       "\n",
       "  date_of_birth_l soc_sec_id_l given_name_r surname_r street_number_r  \\\n",
       "0        19870501      2773283       taylah      reid              25   \n",
       "1        19051230      7491589        jhoel     green             708   \n",
       "2        19540920      8260965      lachlan    clarke              19   \n",
       "\n",
       "         address_1_r      address_2_r       suburb_r postcode_r state_r  \\\n",
       "0  albermarlze place   cypress garden  pennant hills       2210     nsw   \n",
       "1      wangarastreet  gallagher house     burpengary       4670     qld   \n",
       "2     bunbury street        kildurham          nhill       3850     nsw   \n",
       "\n",
       "  date_of_birth_r soc_sec_id_r    labels  \n",
       "0        19571029      7596151  no_match  \n",
       "1             NaN      9018656  no_match  \n",
       "2        19180501      2371774  no_match  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df = remove_nan(generate_febrl_data(init_seed=2))\n",
    "master_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_match    49151\n",
       "match        3409\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.labels.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Development and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Split shape: ( (36792, 22) , (36792,) )\n",
      "Test Split shape: ( (5256, 22) , (5256,) )\n",
      "Validate Split shape: ( (10512, 22) , (10512,) )\n"
     ]
    }
   ],
   "source": [
    "X = master_df.loc[:, ~master_df.columns.isin([\"labels\"])]\n",
    "y = master_df.loc[:, \"labels\"]\n",
    "\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = ttvs(\n",
    "    features=X, targets=y, test_size=0.1, validate_size=0.2)\n",
    "\n",
    "print(f\"Train Split shape: ( {X_train.shape} , {y_train.shape} )\")\n",
    "print(f\"Test Split shape: ( {X_test.shape} , {y_test.shape} )\")\n",
    "print(f\"Validate Split shape: ( {X_val.shape} , {y_val.shape} )\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Parameters for Baseline Model Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training will take in the following external parameters\n",
      "{\n",
      "    \"model_name\": \"bert-base-uncased\",\n",
      "    \"num_epochs\": 1,\n",
      "    \"train_batch_size\": 64,\n",
      "    \"test_batch_size\": 32,\n",
      "    \"margin\": 0.5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "baseline_model_params = get_config()[\"model_params\"]\n",
    "\n",
    "print(f\"Model Training will take in the following external parameters\\n{json.dumps(baseline_model_params, indent=4)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Textual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature set shpae: (36792, 2) and Train target shape 36792\n",
      "Test feature set shpae: (5256, 2) and Test target shape 5256\n",
      "Validation feature set shape: (10512, 2) and Vaiidation target shape 10512\n"
     ]
    }
   ],
   "source": [
    "X_train_txt = generate_textual_features(X_train)\n",
    "X_test_txt = generate_textual_features(X_test)\n",
    "X_val_txt = generate_textual_features(X_val)\n",
    "\n",
    "print(f\"Train feature set shpae: {X_train_txt.shape} and Train target shape {len(y_train)}\\nTest feature set shpae: {X_test_txt.shape} and Test target shape {len(y_test)}\\nValidation feature set shape: {X_val_txt.shape} and Vaiidation target shape {len(y_val)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop Transformer based Siamese Neural Network Model as Baseline Model\n",
    "\n",
    "To start, for this model we can just look at the `sentence_l` and `sentence_r` _\"textual\"_ features we generated as shown above.\n",
    "\n",
    "<!-- \n",
    "![example_siamese](../docs/example_siamese.png)\n",
    "<h6>Image Obtained from Quora Blog Post: https://quoraengineering.quora.com/</h6>  \n",
    " -->\n",
    "  \n",
    "1. distill roberta base model fron huggingface\n",
    "2. for negative pairs (i.e. target variabkes with negative class labels) the margin = 0.5\n",
    "3. as distance metric we use cosine distance (1-cosine_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-21 01:52:02 - Load pretrained SentenceTransformer: bert-base-uncased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad5960be1fa49e692fafb2fdd9aa963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)CoreML/model.mlmodel:   0%|          | 0.00/165k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15346c17942c460fb6b8448c8ad7a4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"weight.bin\";:   0%|          | 0.00/532M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8bb6c15bf048c5896806f61bad0a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ackage/Manifest.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fab9097bba4fafa807c60e047634e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"model.onnx\";:   0%|          | 0.00/532M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-21 01:52:33 - No sentence-transformers model found with name /Users/mustafawaheed/.cache/torch/sentence_transformers/bert-base-uncased. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/mustafawaheed/.cache/torch/sentence_transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-21 01:52:35 - Use pytorch device: cpu\n",
      "2023-10-21 01:52:35 - Evaluate model without training\n",
      "2023-10-21 01:52:35 - Binary Accuracy Evaluation of the model on  dataset in epoch 0 after 0 steps:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cdab8857e54b4e8b87155c2352e011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-21 01:52:40 - Accuracy with Cosine-Similarity:           91.67\t(Threshold: 0.8556)\n",
      "2023-10-21 01:52:40 - F1 with Cosine-Similarity:                 93.55\t(Threshold: 0.8339)\n",
      "2023-10-21 01:52:40 - Precision with Cosine-Similarity:          96.67\n",
      "2023-10-21 01:52:40 - Recall with Cosine-Similarity:             90.62\n",
      "2023-10-21 01:52:40 - Average Precision with Cosine-Similarity:  97.61\n",
      "\n",
      "2023-10-21 01:52:40 - Accuracy with Manhattan-Distance:           93.75\t(Threshold: 101.3777)\n",
      "2023-10-21 01:52:40 - F1 with Manhattan-Distance:                 95.08\t(Threshold: 101.3777)\n",
      "2023-10-21 01:52:40 - Precision with Manhattan-Distance:          100.00\n",
      "2023-10-21 01:52:40 - Recall with Manhattan-Distance:             90.62\n",
      "2023-10-21 01:52:40 - Average Precision with Manhattan-Distance:  97.85\n",
      "\n",
      "2023-10-21 01:52:40 - Accuracy with Euclidean-Distance:           93.75\t(Threshold: 4.5505)\n",
      "2023-10-21 01:52:40 - F1 with Euclidean-Distance:                 95.08\t(Threshold: 4.5505)\n",
      "2023-10-21 01:52:40 - Precision with Euclidean-Distance:          100.00\n",
      "2023-10-21 01:52:40 - Recall with Euclidean-Distance:             90.62\n",
      "2023-10-21 01:52:40 - Average Precision with Euclidean-Distance:  97.83\n",
      "\n",
      "2023-10-21 01:52:40 - Accuracy with Dot-Product:           82.29\t(Threshold: 56.1249)\n",
      "2023-10-21 01:52:40 - F1 with Dot-Product:                 85.95\t(Threshold: 56.1249)\n",
      "2023-10-21 01:52:40 - Precision with Dot-Product:          91.23\n",
      "2023-10-21 01:52:40 - Recall with Dot-Product:             81.25\n",
      "2023-10-21 01:52:40 - Average Precision with Dot-Product:  92.91\n",
      "\n",
      "2023-10-21 01:52:40 - Start Model Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b516581210f459c92b432b22c3aec5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6930b706f3b4eb1a4db125938a0819c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-21 01:53:34 - Binary Accuracy Evaluation of the model on  dataset after epoch 0:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d7e43be0474454ba0c371a33c08c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-21 01:53:39 - Accuracy with Cosine-Similarity:           93.75\t(Threshold: 0.8121)\n",
      "2023-10-21 01:53:39 - F1 with Cosine-Similarity:                 95.08\t(Threshold: 0.8121)\n",
      "2023-10-21 01:53:39 - Precision with Cosine-Similarity:          100.00\n",
      "2023-10-21 01:53:39 - Recall with Cosine-Similarity:             90.62\n",
      "2023-10-21 01:53:39 - Average Precision with Cosine-Similarity:  98.52\n",
      "\n",
      "2023-10-21 01:53:39 - Accuracy with Manhattan-Distance:           93.75\t(Threshold: 104.2180)\n",
      "2023-10-21 01:53:39 - F1 with Manhattan-Distance:                 95.24\t(Threshold: 114.3953)\n",
      "2023-10-21 01:53:39 - Precision with Manhattan-Distance:          96.77\n",
      "2023-10-21 01:53:39 - Recall with Manhattan-Distance:             93.75\n",
      "2023-10-21 01:53:39 - Average Precision with Manhattan-Distance:  98.67\n",
      "\n",
      "2023-10-21 01:53:39 - Accuracy with Euclidean-Distance:           93.75\t(Threshold: 4.7143)\n",
      "2023-10-21 01:53:39 - F1 with Euclidean-Distance:                 95.08\t(Threshold: 4.7143)\n",
      "2023-10-21 01:53:39 - Precision with Euclidean-Distance:          100.00\n",
      "2023-10-21 01:53:39 - Recall with Euclidean-Distance:             90.62\n",
      "2023-10-21 01:53:39 - Average Precision with Euclidean-Distance:  98.65\n",
      "\n",
      "2023-10-21 01:53:39 - Accuracy with Dot-Product:           91.67\t(Threshold: 46.5845)\n",
      "2023-10-21 01:53:39 - F1 with Dot-Product:                 93.75\t(Threshold: 46.5845)\n",
      "2023-10-21 01:53:39 - Precision with Dot-Product:          93.75\n",
      "2023-10-21 01:53:39 - Recall with Dot-Product:             93.75\n",
      "2023-10-21 01:53:39 - Average Precision with Dot-Product:  97.39\n",
      "\n",
      "2023-10-21 01:53:39 - Save model to ../output/models/bert-base-uncased-bsz-64-ep-1-2023-10-21_01-52-02\n",
      "2023-10-21 01:53:40 - Evaluate model performance on test set\n",
      "2023-10-21 01:53:40 - Load pretrained SentenceTransformer: ../output/models/bert-base-uncased-bsz-64-ep-1-2023-10-21_01-52-02\n",
      "2023-10-21 01:53:41 - Use pytorch device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320449561b9c46ad935a530bcb56a525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-21 01:53:46 - Accuracy with Cosine-Similarity:           96.88\t(Threshold: 0.8064)\n",
      "2023-10-21 01:53:46 - F1 with Cosine-Similarity:                 96.77\t(Threshold: 0.8064)\n",
      "2023-10-21 01:53:46 - Precision with Cosine-Similarity:          100.00\n",
      "2023-10-21 01:53:46 - Recall with Cosine-Similarity:             93.75\n",
      "2023-10-21 01:53:46 - Average Precision with Cosine-Similarity:  99.39\n",
      "\n",
      "2023-10-21 01:53:46 - Accuracy with Manhattan-Distance:           96.88\t(Threshold: 104.5131)\n",
      "2023-10-21 01:53:46 - F1 with Manhattan-Distance:                 96.77\t(Threshold: 104.5131)\n",
      "2023-10-21 01:53:46 - Precision with Manhattan-Distance:          100.00\n",
      "2023-10-21 01:53:46 - Recall with Manhattan-Distance:             93.75\n",
      "2023-10-21 01:53:46 - Average Precision with Manhattan-Distance:  99.19\n",
      "\n",
      "2023-10-21 01:53:46 - Accuracy with Euclidean-Distance:           96.88\t(Threshold: 4.7902)\n",
      "2023-10-21 01:53:46 - F1 with Euclidean-Distance:                 96.77\t(Threshold: 4.7902)\n",
      "2023-10-21 01:53:46 - Precision with Euclidean-Distance:          100.00\n",
      "2023-10-21 01:53:46 - Recall with Euclidean-Distance:             93.75\n",
      "2023-10-21 01:53:46 - Average Precision with Euclidean-Distance:  99.04\n",
      "\n",
      "2023-10-21 01:53:46 - Accuracy with Dot-Product:           95.31\t(Threshold: 46.8198)\n",
      "2023-10-21 01:53:46 - F1 with Dot-Product:                 95.52\t(Threshold: 46.8198)\n",
      "2023-10-21 01:53:46 - Precision with Dot-Product:          91.43\n",
      "2023-10-21 01:53:46 - Recall with Dot-Product:             100.00\n",
      "2023-10-21 01:53:46 - Average Precision with Dot-Product:  97.89\n",
      "\n",
      "2023-10-21 01:53:46 - Test Performance Metrics:\n",
      "{\n",
      "    \"accuracy\": 0.96875,\n",
      "    \"accuracy_threshold\": 0.8063812255859375,\n",
      "    \"f1\": 0.967741935483871,\n",
      "    \"f1_threshold\": 0.8063812255859375,\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.9375,\n",
      "    \"ap\": 0.9938830876330876\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "X_train_txt_sample, y_train_sample = sample_xy(X=X_train_txt,y=y_train,num=64)\n",
    "X_test_txt_sample, y_test_sample = sample_xy(X=X_test_txt,y=y_test,num=32)\n",
    "X_val_txt_sample, y_val_sample = sample_xy(X=X_val_txt,y=y_val,num=32)\n",
    "\n",
    "train_txt_baseline(X_train_txt_sample, y_train_sample, X_test_txt_sample, y_test_sample, X_val_txt_sample, y_val_sample, \n",
    "**baseline_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "```bibtex \n",
    "@inproceedings{reimers-2019-sentence-bert,\n",
    "    title     = \"Sentence-BERT: Sentence Embeddings using Siamese   BERT-Networks\",\n",
    "    author    = \"Reimers, Nils and Gurevych, Iryna\",\n",
    "    booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\",\n",
    "    month     = \"11\",\n",
    "    year      = \"2019\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url       = \"https://arxiv.org/abs/1908.10084\",\n",
    "}\n",
    "```\n",
    "  \n",
    "```bibtex  \n",
    "@software{de_bruin_j_2019_3559043,\n",
    "  author       = \"De Bruin, J\",\n",
    "  title        = \"Python Record Linkage Toolkit: A toolkit for record linkage and duplicate detection in Python\",\n",
    "  month        = \"12\",\n",
    "  year         = \"2019\",\n",
    "  publisher    = \"Zenodo\",\n",
    "  version      = \"v0.14\",\n",
    "  doi          = \"10.5281/zenodo.3559043\",\n",
    "  url          = \"https://doi.org/10.5281/zenodo.3559043\"\n",
    "}\n",
    "```\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6428ed0887bfe3dd6d1bd9b847bc5095062b29fc6dadf2105fd27a91eb126d90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
